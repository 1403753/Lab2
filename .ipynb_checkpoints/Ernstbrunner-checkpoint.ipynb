{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3 == yea?': ['democrat',\n",
      "               {'2 == yea?': ['republican',\n",
      "                              {'1 == yea?': ['democrat', 'republican']}]}]}\n",
      "{'3 == yea?': ['democrat', 'republican']}\n",
      "{'3 == yea?': ['democrat',\n",
      "               {'7 == yea?': [{'3 == yea?': ['republican', 'democrat']},\n",
      "                              {'6 == yea?': [{'1 == yea?': ['democrat',\n",
      "                                                            'republican']},\n",
      "                                             'republican']}]}]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "# function definitions\n",
    "\n",
    "def load_data(fname):\n",
    "    data = np.genfromtxt(fname, delimiter=',', dtype=str)\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            if data[i][j] == '?':\n",
    "                data[i][j] = np.random.choice(['y', 'n'])\n",
    "    return data\n",
    "\n",
    "def entropy(X):\n",
    "    unique, counts = np.unique(X, return_counts=True)\n",
    "    px = counts / len(X)\n",
    "    return -np.dot(px, np.log2(px))\n",
    "\n",
    "def compute_gain(S, i):\n",
    "    E = entropy(S)\n",
    "    avg_E = 0\n",
    "    unique, counts = np.unique(i, return_counts=True)\n",
    "    s = 1 / len(S)\n",
    "    for j in range(len(unique)):\n",
    "        idx = np.where(unique[j] == i)[0]\n",
    "        avg_E += len(idx) * s * entropy(S[idx])\n",
    "    return E - avg_E\n",
    "\n",
    "def compute_majority(data):\n",
    "    unique, counts = np.unique(data[:,0], return_counts=True)\n",
    "    return unique[np.argmax(counts)]\n",
    "\n",
    "def ID3(d, n, data):\n",
    "    \n",
    "    if len(np.unique(data[:,0])) == 1:\n",
    "        return compute_majority(data)\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        if data.shape[1] == 1:\n",
    "            return compute_majority(data)\n",
    "   \n",
    "        gains = [compute_gain(data[:,0], data[:,x]) for x in range(1, data.shape[1])]    \n",
    "        \n",
    "        split_column = np.argmax(gains)\n",
    "                \n",
    "        yea_idx = np.where(data[:,split_column] == 'y')[0]\n",
    "        nea_idx = np.where(data[:,split_column] == 'n')[0]\n",
    "        \n",
    "        if (len(nea_idx) == 0) or (len(yea_idx) == 0):\n",
    "            return compute_majority(data)\n",
    "            \n",
    "        data_yea = np.delete(data[yea_idx,:], split_column, 1)\n",
    "        data_nea = np.delete(data[nea_idx,:], split_column, 1)\n",
    "        \n",
    "        # determine question\n",
    "        question = \"{} == {}\".format(split_column, 'yea?')\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        tree = {question: []}\n",
    "        \n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yea = ID3(4,4, data_yea)\n",
    "        nea = ID3(4,4, data_nea)\n",
    "        \n",
    "\n",
    "        if yea == nea:\n",
    "            tree = yea\n",
    "        else:\n",
    "        \n",
    "            tree[question].append(yea)\n",
    "            tree[question].append(nea)\n",
    "        \n",
    "        return tree\n",
    "        \n",
    "\n",
    "\n",
    "def split_data(data, split):\n",
    "    \n",
    "    # create permuted indices for training and test sets\n",
    "    perm = np.random.permutation(np.indices((len(data),))[0])\n",
    "    \n",
    "    # calculate the number of rows according to the given percentage\n",
    "    nrows = int(split * len(data))\n",
    "    training_set = data[perm[:nrows]]\n",
    "    test_set = data[perm[nrows:]]\n",
    "    return training_set, test_set\n",
    "\n",
    "def learning_curve(d, n, training_set, test_set):\n",
    "    # you will probably need additional helper functions\n",
    "    return plot\n",
    "\n",
    "# main\n",
    "\n",
    "data = load_data('house-votes-84.data')\n",
    "\n",
    "k = np.array([1,32,4,5])\n",
    "\n",
    "# set seed before splitting the data\n",
    "np.random.seed(666)\n",
    "tr_s, te_s = split_data(data, .7)\n",
    "\n",
    "pprint(ID3(4,4,tr_s))\n",
    "\n",
    "pprint(ID3(4,4,data))\n",
    "\n",
    "pprint(ID3(4,4,te_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "idea for building a sutree: https://github.com/SebastianMantey/Decision-Tree-from-Scratch/blob/master/notebooks/handling%20continuous%20and%20categorical%20variables.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
